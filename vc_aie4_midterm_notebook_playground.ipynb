{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Engineering Cohort#4 Midterm Notebook Playground"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NOTE - May need to pin langchain_core version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "424a6920-0cea-4e28-dce0-3de6f0a4cc3c"
      },
      "outputs": [],
      "source": [
        "# NOTE!!!\n",
        "# May need to pin version: langchain_core==0.2.38\n",
        "!pip install -U -q langchain langchain-openai langchain_core==0.2.38 langchain-community langchainhub langchain-qdrant langchain_huggingface   langchain-text-splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU qdrant-client pymupdf pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU faiss-cpu unstructured==0.15.7 python-pptx==1.0.2 nltk==3.9.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Note - pin the version of pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip uninstall -y pyarrow\n",
        "!pip install -qU sentence_transformers datasets pyarrow==14.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key here: \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "import pandas as pd\n",
        "from typing import List\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from ragas import evaluate\n",
        "from ragas.metrics import faithfulness, answer_relevancy, answer_correctness, context_recall, context_precision\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "\n",
        "from myutils.rag_pipeline_utils import SimpleTextSplitter, SemanticTextSplitter, VectorStore, AdvancedRetriever\n",
        "from myutils.ragas_pipeline import RagasPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from sentence_transformers import InputExample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 1 - Load the Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Make a local copy of the two pdfs needed for this exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget https://www.whitehouse.gov/wp-content/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf -O ./data/docs_for_rag/Blueprint-for-an-AI-Bill-of-Rights.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# !wget https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.600-1.pdf -O ./data/docs_for_rag/NIST.AI.600-1.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load pdfs into Langchain Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_file_paths = [\n",
        "    './data/docs_for_rag/Blueprint-for-an-AI-Bill-of-Rights.pdf',\n",
        "    './data/docs_for_rag/NIST.AI.600-1.pdf'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from myutils.rag_pipeline_utils import load_all_pdfs\n",
        "\n",
        "documents = load_all_pdfs(pdf_file_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quick Overview of Documents\n",
        "\n",
        "a.  2022: Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People\n",
        "    \n",
        "This is really two docs in one\n",
        "first doc sets up five principles and practices\n",
        "second one is labeled a technical companion; it expands on each principle as well as how to operationalize it; each principle is reiterated, followed by an articulation of what the principle is important, what should be expected of automated systems in regard to following this principle, and examples of how these principles can move into practice.\n",
        "\n",
        "\n",
        "b.  2024: National Institute of Standards and Technology (NIST) Artificial Intelligent Risk Management Framework\n",
        "\n",
        "First part describes the risks as well as Trustworthy AI characteristics to mitigate the risk\n",
        "Second part, in tabular form, describes mitigation plan for each risks; each risk is identified in the table by a serial number based on the first part of the document rather than by the actual name of the risk."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chunking Strategy\n",
        "\n",
        "It is clear that chunking strategies should account for the semantics in the document, as well as the fact that there are strong connections between the first and second parts of the document.  This comment applies to both documents in this assignment.\n",
        "\n",
        "I will examine two alternatives:\n",
        "\n",
        "(a) BASELINE: use the Swiss-army-knife chunking approach: RecursiveCharacterTextSplitter\n",
        "\n",
        "(b) ADVANCED: Semantic Chunking\n",
        "\n",
        "\n",
        "\n",
        "WHY I CHOSE THESE TWO CHUNKING STRATEGIES\n",
        "1. RecursiveCharacterTextSplitter: if the chunk_size and chunk_overlap are set to reasonable numbers, this approach is surprisingly effective across a range of document content.  It is cost-effective, relatively easy to tune if needed, is well-suited for answering queries that are SIMPLE and those that require MULTI-CONTEXT.\n",
        "\n",
        "\n",
        "2. Semantic chunking has great appeal as it groups content that is contiguous and semantically similar in a single chunk.  To that end, the chunk sizes may be rather uneven.  Advantage: It avoids artificially splitting content that may be very similar into multiple chunks which would make the retriever work harder during the retrieval process and/or perhaps miss relevant context.  The downside is that it is not as cost-effective as it requires the use of an LLM during the chunking process.  It is likely to perform well for MULTI-CONTEXT and potentially queries that require REASONING."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Formulate and Load My Test Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_test_questions(filename):\n",
        "    \"\"\"\n",
        "    Loads a text file with questions\n",
        "\n",
        "    Input\n",
        "        name of file which contains a set of questions to test the RAG pipeline\n",
        "    \n",
        "    Output\n",
        "        List of questions\n",
        "    \"\"\"\n",
        "    with open(filename) as f:\n",
        "        all_q = f.read()\n",
        "        all_q_list = all_q.split('\\n')\n",
        "    return all_q_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_test_questions = load_test_questions(filename='./data/rag_questions_and_answers/my_test_questions.txt')\n",
        "my_test_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 2 - Quick End-to-end Prototype RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set Up RAG Template and RAG Prompt\n",
        "> NOTE that the RAG template and RAG Prompt below will be used throughout this exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "rag_template = \"\"\"\n",
        "Use the provided context to answer the following question.\n",
        "If you can't answer the question based on the context, say you don't know.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(template=rag_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set Up OpenAI Embeddings and Chat Model For Use in Prototype and for Comparison Throughout This Exercise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai_embeddings_small = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "openai_embeddings_small_dimension = 1536\n",
        "\n",
        "openai_embeddings_small_context_window = 8191\n",
        "\n",
        "openai_chat_gpt4omini = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the large embeddings in Semantic Chunking below!!!\n",
        "openai_embeddings_large = OpenAIEmbeddings(model='text-embedding-3-large')\n",
        "openai_embeddings_large_dimension = 3072\n",
        "\n",
        "openai_embeddings_large_context_window = 8191\n",
        "\n",
        "# Set up the lmore performant chat model just in case I decide to use it later...\n",
        "openai_chat_gpt4o = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Snowflake-arctic-embed-m Model (Will be Finetuned Later in The Exercise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model_id = \"Snowflake/snowflake-arctic-embed-m\"\n",
        "model = SentenceTransformer(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_original_embeddings = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-m\")\n",
        "arctic_original_embeddings_dimension = 768\n",
        "arctic_original_context_window_in_tokens = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "long_model_id = \"Snowflake/snowflake-arctic-embed-m-long\"\n",
        "long_model = SentenceTransformer(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_long_original_embeddings = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-m-long\")\n",
        "arctic_long_original_embeddings_dimension = 768\n",
        "arctic_long_original_context_window_in_tokens =  2048"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chunk Documents Using Recursive Character Text Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk_size = 1000\n",
        "chunk_overlap = 300\n",
        "\n",
        "# instantiate baseline text splitter -\n",
        "# NOTE!!! The `SimpleTextSplitter` below is my wrapper around Langchain RecursiveCharacterTextSplitter!!!!\n",
        "# (see module for the code if needed)\n",
        "baseline_text_splitter = \\\n",
        "    SimpleTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, documents=documents)\n",
        "\n",
        "# split text for baseline case\n",
        "baseline_text_splits = baseline_text_splitter.split_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(baseline_text_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chunk Documents Using Semantic Chunking - NOTE Using OpenAI Embeddings Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instantiate semantic text splitter\n",
        "#  NOTE!!!! SemanticTextSplitter is my wrapper around Langchain SemanticChunker\n",
        "#  see my module for code if needed\n",
        "# NOTE!!! I use openai large embeddings model to get the best possible representation of the semantics of sentences\n",
        "# and to ensure high-quality semantic chunking\n",
        "sem_text_splitter = \\\n",
        "    SemanticTextSplitter(llm_embeddings=openai_embeddings_large, threshold_type=\"interquartile\", documents=documents)\n",
        "\n",
        "# split text for semantic-chunking case\n",
        "sem_text_splits = sem_text_splitter.split_text()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vibe Check on My Test Questions - Read This First!!!\n",
        "\n",
        "NOTE:  Four RAG Pipelines are run below!!!  These are:\n",
        "\n",
        "1.  `Demo_Baseline_OpenAI`: This uses baseline chunking (`RecursiveCharacterTextSplitter`) and OpenAI embeddings as a Demo.\n",
        "\n",
        "2.  `Demo_Semantic_OpenAI`: uses semantic chunking (`SemanticChunker`) and OpenAI embeddings as a Demo.\n",
        "\n",
        "3.  `Baseline_Arctic_Original`: uses baseline chunking and `Snowflake/snowflake-arctic-embed-m` model embeddings.\n",
        "\n",
        "4.  `Semantic_Arctic_Original`: uses semantic chunking and `Snowflake/snowflake-arctic-embed-m` model embeddings.\n",
        "\n",
        "NOTE!!!\n",
        "Later in this notebook, I will finetune the `Snowflake/snowflake-arctic-embed-m` model embeddings and will then compare the finetuned embeddings from this model against the runs in 3. and 4. above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from myutils.rag_pipeline_utils import get_vibe_check_on_list_of_questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_openai_retrieval_chain, baseline_openai_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Demo_Baseline_OpenAI\",\n",
        "                                        embeddings=openai_embeddings_small,  # <- openai embeddings\n",
        "                                        embed_dim=openai_embeddings_small_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=baseline_text_splits, # <- baseline chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_openai_retrieval_chain, sem_openai_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Demo_Semantic_OpenAI\",\n",
        "                                        embeddings=openai_embeddings_small, # <- openai embeddings\n",
        "                                        embed_dim=openai_embeddings_small_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=sem_text_splits, # <- semantic chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_arctic_original_retrieval_chain, baseline_arctic_original_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Baseline_Arctic_Original\",\n",
        "                                        embeddings=arctic_original_embeddings, # <- arctic original embeddings\n",
        "                                        embed_dim=arctic_original_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=baseline_text_splits, # <- baseline chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_arctic_original_retrieval_chain.invoke({'question': 'What rights do I have to ensure protection against algorithmic discrimination?'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_arctic_original_retrieval_chain, sem_arctic_original_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Semantic_Arctic_Original\",\n",
        "                                        embeddings=arctic_original_embeddings, # <- arctic original embeddings\n",
        "                                        embed_dim=arctic_original_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=sem_text_splits, # <- semantic chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_arctic_original_retrieval_chain.invoke({'question': 'What rights do I have to ensure protection against algorithmic discrimination?'})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save Test Questions and Answers in File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "def save_df_to_csv(q_a_data, csvfilename):\n",
        "    qa_df = pd.DataFrame(q_a_data, \n",
        "                         columns=['questions', 'answers'])\n",
        "    \n",
        "    filepath = Path(csvfilename)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    qa_df.to_csv(filepath, index=False)\n",
        "    return\n",
        "\n",
        "\n",
        "save_df_to_csv(baseline_openai_q_and_a, \n",
        "               csvfilename='./data/rag_questions_and_answers/baseline_openai_test_q_and_a.csv')\n",
        "\n",
        "save_df_to_csv(sem_openai_q_and_a, \n",
        "               csvfilename='./data/rag_questions_and_answers/sem_openai_test_q_and_a.csv')\n",
        "\n",
        "save_df_to_csv(baseline_arctic_original_q_and_a, \n",
        "               csvfilename='./data/rag_questions_and_answers/baseline_arctic_original_test_q_and_a.csv')\n",
        "\n",
        "save_df_to_csv(sem_arctic_original_q_and_a, \n",
        "               csvfilename='./data/rag_questions_and_answers/sem_arctic_original_test_q_and_a.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 3 - Synthetically Generate Test Questions Using the RAGAS Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set Up RAGAS Pipeline Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LLM models used in RAGAS pipeline\n",
        "ragas_generator_llm_model = 'gpt-3.5-turbo'\n",
        "ragas_critic_llm_model = 'gpt-4o-mini'\n",
        "\n",
        "# embeddings used for RAGAS pipeline\n",
        "ragas_openai_embeddings_model = 'text-embedding-3-small'\n",
        "\n",
        "# text splitter params\n",
        "ragas_chunk_size = 1500\n",
        "ragas_chunk_overlap = 500\n",
        "\n",
        "# number of qa pairs needed - reduce if running into rate limit issues\n",
        "ragas_number_of_qa_pairs = 20\n",
        "\n",
        "# initialize distributions - desired distribution of question types\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "# name of file to persist RAGAS Q&A on disk\n",
        "ragas_testset_filename = \"./data/rag_questions_and_answers/ragas_questions_and_answers.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FLAG TO INDICATE IF RAGAS TESTSET SHOULD BE GENERATED IN THIS RUN\n",
        "# IF it is run, note the cost and time estimate below!!!\n",
        "generate_ragas_testset_now = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up list of RAGAS metrics used below\n",
        "ragas_metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Instantiate RAGAS Pipeline, Run Pipeline, Generate Test Questions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE - this cell will incur significant cost due to SDG's use of OpenAI models\n",
        "# Time taken on my local machine: ~ 15 mins\n",
        "\n",
        "ragas_pipeline = RagasPipeline(\n",
        "        generator_llm_model=ragas_generator_llm_model,\n",
        "        critic_llm_model=ragas_critic_llm_model,\n",
        "        embedding_model=ragas_openai_embeddings_model,\n",
        "        number_of_qa_pairs=ragas_number_of_qa_pairs,\n",
        "        chunk_size=ragas_chunk_size,\n",
        "        chunk_overlap=ragas_chunk_overlap,\n",
        "        documents=documents,\n",
        "        distributions=distributions\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if generate_ragas_testset_now is True:\n",
        "    ragas_testset_df = ragas_pipeline.generate_testset()\n",
        "    ragas_testset_df.to_csv(ragas_testset_filename)\n",
        "else:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load RAGAS Q&A from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "ragas_test_df = pd.read_csv(ragas_testset_filename)\n",
        "ragas_test_questions = ragas_test_df[\"question\"].values.tolist()\n",
        "ragas_test_groundtruths = ragas_test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate RAG Pipeline Using RAGAS Generated Synthetic Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_openai_results, baseline_openai_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(baseline_openai_retrieval_chain, # <- baseline chunking + openai embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_openai_results, sem_openai_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(sem_openai_retrieval_chain, # <- semantic chunking + openai embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_arctic_original_results, baseline_arctic_original_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(baseline_arctic_original_retrieval_chain, # <- baseline chunking + arctic orig embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_arctic_original_results, sem_arctic_original_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(sem_arctic_original_retrieval_chain, # <- semantic chunking + arctic orig embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare The Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_baseline_openai = pd.DataFrame(list(baseline_openai_results.items()), columns=['Metric', 'BaselineChunkOpenAI'])\n",
        "df_sem_openai = pd.DataFrame(list(sem_openai_results.items()), columns=['Metric', 'SemanticChunkOpenAI'])\n",
        "df_merged_openai = pd.merge(df_baseline_openai, df_sem_openai, on='Metric')\n",
        "\n",
        "df_baseline_arctic_original = pd.DataFrame(list(baseline_arctic_original_results.items()), columns=['Metric', 'BaselineChunkArcticOrig'])\n",
        "df_sem_arctic_original = pd.DataFrame(list(sem_arctic_original_results.items()), columns=['Metric', 'SemanticChunkArcticOrig'])\n",
        "df_merged_arctic_original = pd.merge(df_baseline_arctic_original, df_sem_arctic_original, on='Metric')\n",
        "\n",
        "df_all_merged = pd.merge(df_merged_openai, df_merged_arctic_original, on='Metric')\n",
        "\n",
        "df_all_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis of Results - Needs Updating!!!!\n",
        "\n",
        "1.  The results with `Semantic Chunking` seem to be dramatically improved in `RETRIEVAL`-focused metrics like `context_recall` and `answer_relevancy`.\n",
        "\n",
        "2.  Even in measures like `faithfulness` that primarily assesses generation part of the pipeline, the results seem quite improved.\n",
        "\n",
        "3.  Given other results, I would have expected `answer_correctness` to be higher.  It would be useful to dig into factual similarity and semantic similarity differences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## STEP 4 - Fine-tuning Embeddings for RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from myutils.finetuning import PrepareDataForFinetuning, FineTuneModelAndEvaluateRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdft = PrepareDataForFinetuning(all_splits=baseline_text_splits,\n",
        "                                train_val_test_fraction=[0.80, 0.10, 0.10],\n",
        "                                train_val_test_split_type='random',\n",
        "                                random_seed=69,\n",
        "                                qa_chat_model_name='gpt-4o-mini',\n",
        "                                n_questions=3,\n",
        "                                batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdft.run_all_prep_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evr = FineTuneModelAndEvaluateRetriever(train_data=pdft.train_dataset,\n",
        "                                        val_data=pdft.val_dataset,\n",
        "                                        test_data=pdft.test_dataset,\n",
        "                                        batch_size=64,\n",
        "                                        base_model_id='Snowflake/snowflake-arctic-embed-m',\n",
        "                                        matryoshka_dimensions=[768, 512, 256, 128, 64],\n",
        "                                        number_of_training_epochs=5,\n",
        "                                        finetuned_model_output_path='finetuned_arctic',\n",
        "                                        evaluation_steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evr.run_steps_to_finetune_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_finetuned_model = SentenceTransformer('finetuned_arctic')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_finetuned_model.push_to_hub(\"vincha77/finetuned_arctic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "## code here to pull from hub\n",
        "model_id = \"vincha77/finetuned_arctic\"\n",
        "arctic_finetuned_model = SentenceTransformer(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_finetuned_embeddings = HuggingFaceEmbeddings(model_name=\"vincha77/finetuned_arctic\")\n",
        "arctic_finetuned_embeddings_dimension = 768\n",
        "arctic_finetuned_context_window_in_tokens = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "te3_results = evr.evaluate_embeddings_model(openai_embeddings_small, top_k_for_retrieval=5)\n",
        "\n",
        "te3_results_df = pd.DataFrame(te3_results)\n",
        "\n",
        "te3_hit_rate = te3_results_df[\"is_hit\"].mean()\n",
        "te3_hit_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arctic_embed_m_results = evr.evaluate_embeddings_model(arctic_original_embeddings, top_k_for_retrieval=5)\n",
        "\n",
        "arctic_embed_m_results_df = pd.DataFrame(arctic_embed_m_results)\n",
        "\n",
        "arctic_embed_m_hit_rate = arctic_embed_m_results_df[\"is_hit\"].mean()\n",
        "arctic_embed_m_hit_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "finetuned_results = evr.evaluate_embeddings_model(arctic_finetuned_embeddings, top_k_for_retrieval=5)\n",
        "\n",
        "finetuned_results_df = pd.DataFrame(finetuned_results)\n",
        "\n",
        "finetuned_hit_rate = finetuned_results_df[\"is_hit\"].mean()\n",
        "finetuned_hit_rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vibe Checking the RAG Pipeline\n",
        "\n",
        "We're going to use our RAG pipeline to vibe check on some common phrases now that we've modified it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chunk Documents Using Recursive Character Text Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_chunk_size = 600\n",
        "new_chunk_overlap = 200\n",
        "\n",
        "# instantiate baseline text splitter -\n",
        "# NOTE!!! The `SimpleTextSplitter` below is my wrapper around Langchain RecursiveCharacterTextSplitter!!!!\n",
        "# (see module for the code if needed)\n",
        "new_baseline_text_splitter = \\\n",
        "    SimpleTextSplitter(chunk_size=new_chunk_size, chunk_overlap=new_chunk_overlap, documents=documents)\n",
        "\n",
        "# split text for baseline case\n",
        "new_baseline_text_splits = new_baseline_text_splitter.split_text()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(new_baseline_text_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Chunk Documents Using Semantic Chunking - NOTE Using OpenAI Embeddings Large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# instantiate semantic text splitter\n",
        "#  NOTE!!!! SemanticTextSplitter is my wrapper around Langchain SemanticChunker\n",
        "#  see my module for code if needed\n",
        "# NOTE!!! I use openai large embeddings model to get the best possible representation of the semantics of sentences\n",
        "# and to ensure high-quality semantic chunking\n",
        "new_sem_text_splitter = \\\n",
        "    SemanticTextSplitter(llm_embeddings=openai_embeddings_large, threshold_type=\"interquartile\", documents=documents)\n",
        "\n",
        "# split text for semantic-chunking case\n",
        "new_sem_text_splits = new_sem_text_splitter.split_text()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vibe Check on My Test Questions - Read This First!!!\n",
        "\n",
        "NOTE:  Four RAG Pipelines are run below!!!  These are:\n",
        "\n",
        "1.  `Demo_Baseline_OpenAI`: This uses baseline chunking (`RecursiveCharacterTextSplitter`) and OpenAI embeddings as a Demo.\n",
        "\n",
        "2.  `Demo_Semantic_OpenAI`: uses semantic chunking (`SemanticChunker`) and OpenAI embeddings as a Demo.\n",
        "\n",
        "3.  `Baseline_Arctic_Original`: uses baseline chunking and `Snowflake/snowflake-arctic-embed-m` model embeddings.\n",
        "\n",
        "4.  `Semantic_Arctic_Original`: uses semantic chunking and `Snowflake/snowflake-arctic-embed-m` model embeddings.\n",
        "\n",
        "NOTE!!!\n",
        "Later in this notebook, I will finetune the `Snowflake/snowflake-arctic-embed-m` model embeddings and will then compare the finetuned embeddings from this model against the runs in 3. and 4. above\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_baseline_arctic_original_retrieval_chain, new_baseline_arctic_original_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Baseline_Arctic_Original\",\n",
        "                                        embeddings=arctic_original_embeddings, # <- arctic original embeddings\n",
        "                                        embed_dim=arctic_original_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=new_baseline_text_splits, # <- NEW baseline chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_baseline_arctic_finetuned_retrieval_chain, new_baseline_arctic_finetuned_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Baseline_Arctic_Finetuned\",\n",
        "                                        embeddings=arctic_finetuned_embeddings, # <- arctic finetuned embeddings\n",
        "                                        embed_dim=arctic_finetuned_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=new_baseline_text_splits, # <- NEW baseline chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sem_arctic_original_retrieval_chain, new_sem_arctic_original_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Semantic_Arctic_Original\",\n",
        "                                        embeddings=arctic_original_embeddings, # <- arctic original embeddings\n",
        "                                        embed_dim=arctic_original_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=new_sem_text_splits, # <- NEW semantic chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_sem_arctic_finetuned_retrieval_chain, new_sem_arctic_finetuned_q_and_a = \\\n",
        "    get_vibe_check_on_list_of_questions(collection_name=\"Semantic_Arctic_Finetuned\",\n",
        "                                        embeddings=arctic_finetuned_embeddings, # <- arctic finetuned embeddings\n",
        "                                        embed_dim=arctic_finetuned_embeddings_dimension,\n",
        "                                        prompt=rag_prompt,\n",
        "                                        llm=openai_chat_gpt4omini,\n",
        "                                        text_splits=new_sem_text_splits, # <- NEW semantic chunking\n",
        "                                        list_of_questions=my_test_questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate RAG Pipeline Using RAGAS Generated Synthetic Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_arctic_original_results, baseline_arctic_original_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(new_baseline_arctic_original_retrieval_chain, # <- baseline chunking + arctic orig embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_arctic_finetuned_results, baseline_arctic_finetuned_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(new_baseline_arctic_finetuned_retrieval_chain, # <- baseline chunking + arctic finetuned embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_arctic_original_results, sem_arctic_original_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(new_sem_arctic_original_retrieval_chain, # <- semantic chunking + arctic orig embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sem_arctic_finetuned_results, sem_arctic_finetuned_results_df = \\\n",
        "    ragas_pipeline.ragas_eval_of_rag_pipeline(new_sem_arctic_finetuned_retrieval_chain, # <- semantic chunking + arctic finetuned embeddings\n",
        "                                              ragas_test_questions, \n",
        "                                              ragas_test_groundtruths, \n",
        "                                              ragas_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compare The Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_baseline_arctic_original = pd.DataFrame(list(baseline_arctic_original_results.items()), columns=['Metric', 'BaselineChunkArcticOrig'])\n",
        "df_baseline_arctic_finetuned = pd.DataFrame(list(baseline_arctic_finetuned_results.items()), columns=['Metric', 'BaselineChunkArcticFinetuned'])\n",
        "df_merged_arctic_baseline = pd.merge(df_baseline_arctic_original, df_baseline_arctic_finetuned, on='Metric')\n",
        "\n",
        "df_sem_arctic_original = pd.DataFrame(list(sem_arctic_original_results.items()), columns=['Metric', 'SemanticChunkArcticOrig'])\n",
        "df_sem_arctic_finetuned = pd.DataFrame(list(sem_arctic_finetuned_results.items()), columns=['Metric', 'SemanticChunkArcticFinetuned'])\n",
        "df_merged_arctic_sem = pd.merge(df_sem_arctic_original, df_sem_arctic_finetuned, on='Metric')\n",
        "\n",
        "df_all_merged = pd.merge(df_merged_arctic_baseline, df_merged_arctic_sem, on='Metric')\n",
        "\n",
        "df_all_merged"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Clyykfe6xOIo"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00afceb39c074975b6b88d6d0d4d2901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9932859168ad436e9aeef09279b534b1",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474f44771cb04a4693585273a03a5548",
            "value": 95
          }
        },
        "0267d8c4d9cc48b0a4d60d206de62a91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c3173c05f54539ae025937b1525e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0be98b57b4894cf9a92818ae1dd72976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda4d1ec0f0043c8b4d254a4ada3e9bf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b24ed8b36764c39aef39c92430fdc1d",
            "value": 20
          }
        },
        "126c30cc07c4452ab73fefce09dab617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1535c2c75a104f3abb262c5fb7859c14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b24ed8b36764c39aef39c92430fdc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c0f9aeab5de4e32af8bfef423a64f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0267d8c4d9cc48b0a4d60d206de62a91",
            "placeholder": "​",
            "style": "IPY_MODEL_126c30cc07c4452ab73fefce09dab617",
            "value": "Generating: 100%"
          }
        },
        "1e2026abc1314d3caf37d74af7a407e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32bc4bb09af4ac5a608e56f87317596",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b53095cea92740dfb967120a77310283",
            "value": 95
          }
        },
        "22c5f6324de545ba814402c3f71d84f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353b6b9a974048499d854774fe4c882c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2e50139c234d19ac3e32515e575883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474f44771cb04a4693585273a03a5548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d9ba78dc78040f494df9122ddc7ba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4e76e5d4fba404a9ed4ff059f3a0c04",
              "IPY_MODEL_1e2026abc1314d3caf37d74af7a407e7",
              "IPY_MODEL_fb306876e3244dc69312e2af46c4da02"
            ],
            "layout": "IPY_MODEL_b319ae78e30d437c81f07d5a062ba805"
          }
        },
        "63d6044414e24c5ea55efa925f7a3b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754827da55fa4240bce3710048d1645b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd96dd318c1b4e1481c039321e052081",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2e50139c234d19ac3e32515e575883",
            "value": "embedding nodes: 100%"
          }
        },
        "764b7b6827c9437b90c9c948b9f1037b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771597df670f417794f66408b05a7eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab80823e1344b638ddd1646367a6ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b61421d62964b00ba440ecba21f4b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353b6b9a974048499d854774fe4c882c",
            "max": 1248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09c3173c05f54539ae025937b1525e90",
            "value": 1248
          }
        },
        "8025a0f161d3475794daa9cd88209d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824fe37b12d4414a9376e266ddd086f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9496fc3f26cb42ec9ace36175eb14906",
            "placeholder": "​",
            "style": "IPY_MODEL_8025a0f161d3475794daa9cd88209d5c",
            "value": "Evaluating: 100%"
          }
        },
        "90af75e58cef440a8d38ee6621e0f4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f2e2d3123c4cd88d7c5755342ae154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9496fc3f26cb42ec9ace36175eb14906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9932859168ad436e9aeef09279b534b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a40d4ba626f4563b062a5765325d8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c0f9aeab5de4e32af8bfef423a64f3b",
              "IPY_MODEL_0be98b57b4894cf9a92818ae1dd72976",
              "IPY_MODEL_c7550f460273484a913d211381630626"
            ],
            "layout": "IPY_MODEL_ba8f638b7f6343d9b07cce6e54e9be1c"
          }
        },
        "9ccac42dd9f04713b0ed9fe09c35b5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b319ae78e30d437c81f07d5a062ba805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53095cea92740dfb967120a77310283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba8f638b7f6343d9b07cce6e54e9be1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd96dd318c1b4e1481c039321e052081": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda4d1ec0f0043c8b4d254a4ada3e9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d31c6cf07143aea1bbe76aa13fbca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754827da55fa4240bce3710048d1645b",
              "IPY_MODEL_7b61421d62964b00ba440ecba21f4b52",
              "IPY_MODEL_c67b66e1f2d34ce4b10789fc2fca5843"
            ],
            "layout": "IPY_MODEL_9ccac42dd9f04713b0ed9fe09c35b5b0"
          }
        },
        "c67b66e1f2d34ce4b10789fc2fca5843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa998b429774e4eb6aaaa5477bb6977",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab80823e1344b638ddd1646367a6ce6",
            "value": " 1248/1248 [07:00&lt;00:00, 49.86s/it]"
          }
        },
        "c7550f460273484a913d211381630626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1535c2c75a104f3abb262c5fb7859c14",
            "placeholder": "​",
            "style": "IPY_MODEL_92f2e2d3123c4cd88d7c5755342ae154",
            "value": " 20/20 [01:17&lt;00:00, 12.75s/it]"
          }
        },
        "ce0b10aca9064bc092cf3305eb0dab04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ced3689d335c4f1ca62d39b908d6cb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824fe37b12d4414a9376e266ddd086f5",
              "IPY_MODEL_00afceb39c074975b6b88d6d0d4d2901",
              "IPY_MODEL_e8c20cb22ecb40dbaf61959fc7d087cb"
            ],
            "layout": "IPY_MODEL_771597df670f417794f66408b05a7eb9"
          }
        },
        "d020211480b149cab1761b14ae631eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32bc4bb09af4ac5a608e56f87317596": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e76e5d4fba404a9ed4ff059f3a0c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c5f6324de545ba814402c3f71d84f1",
            "placeholder": "​",
            "style": "IPY_MODEL_764b7b6827c9437b90c9c948b9f1037b",
            "value": "Evaluating: 100%"
          }
        },
        "e8c20cb22ecb40dbaf61959fc7d087cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90af75e58cef440a8d38ee6621e0f4d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0b10aca9064bc092cf3305eb0dab04",
            "value": " 95/95 [00:30&lt;00:00,  1.25it/s]"
          }
        },
        "faa998b429774e4eb6aaaa5477bb6977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb306876e3244dc69312e2af46c4da02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d020211480b149cab1761b14ae631eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_63d6044414e24c5ea55efa925f7a3b56",
            "value": " 95/95 [00:24&lt;00:00,  1.20it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
